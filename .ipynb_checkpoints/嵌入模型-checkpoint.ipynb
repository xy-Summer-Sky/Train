{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T04:59:50.579193Z",
     "start_time": "2024-11-08T04:59:39.348644Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/train39/lib/python3.9/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:13: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyPDFDirectoryLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter, CharacterTextSplitter,TokenTextSplitter\n",
    "from langchain_community.embeddings.huggingface import HuggingFaceEmbeddings\n",
    "from langchain_community.retrievers.bm25 import BM25Retriever\n",
    "from langchain.retrievers import EnsembleRetriever\n",
    "from langchain_community.vectorstores import Chroma, FAISS\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableParallel\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "import gc\n",
    "import re\n",
    "from IPython.display import display\n",
    "\n",
    "DOCS_DIR = './A/A_document'\n",
    "EMB_MODEL = './bge-large-zh-v1.5'\n",
    "RERANK_MODEL = \"./bge-reranker-large\"\n",
    "PERSIST_DIR = './vectordb' \n",
    "QUERY_DIR = './A/A_question.csv'\n",
    "SUB_DIR = './submit_example.csv'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T04:59:50.657198Z",
     "start_time": "2024-11-08T04:59:50.596199Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ques_id</th>\n",
       "      <th>question</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>根据年度报告，2022年中国联通在向数字科技领军企业转变的过程中实现了哪些维度的转型升级？</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>告诉我2022年联通产业互联网收入的同比增长速度。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>根据2022年度报告，中国联通的企业定位是什么？</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ques_id                                       question\n",
       "0        1  根据年度报告，2022年中国联通在向数字科技领军企业转变的过程中实现了哪些维度的转型升级？\n",
       "1        2                      告诉我2022年联通产业互联网收入的同比增长速度。\n",
       "2        3                       根据2022年度报告，中国联通的企业定位是什么？"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ques_id</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>根据年度报告，2022年中国联通在向数字科技领军企业转变的过程中实现了哪些维度的转型升级？</td>\n",
       "      <td>我们坚定践行网络强国、数字中国、智慧社会战略部署，今天的中国联通，正在从传统运营商加速向数字...</td>\n",
       "      <td>-0.02707982249557972,-0.009818901307880878,-0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>告诉我2022年联通产业互联网收入的同比增长速度。</td>\n",
       "      <td>我们坚定践行网络强国、数字中国、智慧社会战略部署，今天的中国联通，正在从传统运营商加速向数字...</td>\n",
       "      <td>-0.02707982249557972,-0.009818901307880878,-0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>根据2022年度报告，中国联通的企业定位是什么？</td>\n",
       "      <td>我们坚定践行网络强国、数字中国、智慧社会战略部署，今天的中国联通，正在从传统运营商加速向数字...</td>\n",
       "      <td>-0.02707982249557972,-0.009818901307880878,-0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ques_id                                       question  \\\n",
       "0        1  根据年度报告，2022年中国联通在向数字科技领军企业转变的过程中实现了哪些维度的转型升级？   \n",
       "1        2                      告诉我2022年联通产业互联网收入的同比增长速度。   \n",
       "2        3                       根据2022年度报告，中国联通的企业定位是什么？   \n",
       "\n",
       "                                              answer  \\\n",
       "0  我们坚定践行网络强国、数字中国、智慧社会战略部署，今天的中国联通，正在从传统运营商加速向数字...   \n",
       "1  我们坚定践行网络强国、数字中国、智慧社会战略部署，今天的中国联通，正在从传统运营商加速向数字...   \n",
       "2  我们坚定践行网络强国、数字中国、智慧社会战略部署，今天的中国联通，正在从传统运营商加速向数字...   \n",
       "\n",
       "                                           embedding  \n",
       "0  -0.02707982249557972,-0.009818901307880878,-0....  \n",
       "1  -0.02707982249557972,-0.009818901307880878,-0....  \n",
       "2  -0.02707982249557972,-0.009818901307880878,-0....  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "query = pd.read_csv(QUERY_DIR)\n",
    "sub = pd.read_csv(\"./submit_example.csv\")\n",
    "display(query.head(3))\n",
    "display(sub.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PDF文档解析和切分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T05:00:33.751532Z",
     "start_time": "2024-11-08T04:59:51.353879Z"
    }
   },
   "outputs": [],
   "source": [
    "loader = PyPDFDirectoryLoader(DOCS_DIR)\n",
    "pages = loader.load_and_split()\n",
    "pdf_list = os.listdir(DOCS_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T05:00:33.798171Z",
     "start_time": "2024-11-08T05:00:33.764543Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 114/114 [00:00<00:00, 8270.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "key:pdf value:text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "pdf_text = { pdf_page.metadata['source'][-8:]:'' for pdf_page  in pages }\n",
    "for pdf in tqdm(pdf_list):\n",
    "    for pdf_page in pages:\n",
    "        if pdf in pdf_page.metadata['source']:\n",
    "            pdf_text[pdf] += pdf_page.page_content\n",
    "        else:\n",
    "            continue\n",
    "print('key:pdf value:text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T05:00:33.827680Z",
     "start_time": "2024-11-08T05:00:33.814687Z"
    }
   },
   "outputs": [],
   "source": [
    "def filter_text(text):\n",
    "    # 页码清除 效果不好\n",
    "#     page_id_pattern1 = r'\\n\\d+\\s*/\\s*\\d+\\s*\\n'\n",
    "#     page_id_pattern2 = r'\\n\\d+\\n'\n",
    "#     page_id_pattern3 = r'\\n\\d+\\s*?'\n",
    "\n",
    "#     page_id_pattern = page_id_pattern1+'|'+page_id_pattern2+'|'+page_id_pattern3\n",
    "#     text = re.sub(page_id_pattern,'',text)\n",
    "    \n",
    "    # '\\n', ' ' 删除\n",
    "    text = text.replace('\\n','').replace(' ','')\n",
    "    \n",
    "    # 删除页码\n",
    "    \n",
    "    # 删除本文档为2024CCFBDC***\n",
    "    head_pattern = '本文档为2024CCFBDCI比赛用语料的一部分。[^\\s]+仅允许在本次比赛中使用。'\n",
    "    # news_pattern\n",
    "    pattern1 = r\"发布时间：[^\\s]+发布人：新闻宣传中心\"\n",
    "    pattern2 = r\"发布时间：[^\\s]+发布人：新闻发布人\"\n",
    "    pattern3 =  r'发布时间：\\d{4}年\\d{1,2}月\\d{1,2}日'\n",
    "    news_pattern = head_pattern+'|'+pattern1+'|'+pattern2+'|'+pattern3\n",
    "    text = re.sub(news_pattern,'',text)\n",
    "    \n",
    "    \n",
    "    # report_pattern\n",
    "    report_pattern1 = '第一节重要提示[^\\s]+本次利润分配方案尚需提交本公司股东大会审议。'\n",
    "    report_pattern12 = '一重要提示[^\\s]+股东大会审议。'\n",
    "    report_pattern13 = '一、重要提示[^\\s]+季度报告未经审计。'\n",
    "    report_pattern2 = '本公司董事会及全体董事保证本公告内容不存在任何虚假记载、[^\\s]+季度财务报表是否经审计□是√否'\n",
    "    report_pattern3 = '中国联合网络通信股份有限公司（简称“公司”）董事会审计委员会根据相关法律法规、[^\\s]+汇报如下：'\n",
    "    report_pattern = report_pattern1+'|'+report_pattern12+'|'+report_pattern13+'|'+report_pattern2+'|'+report_pattern3\n",
    "    text = re.sub( report_pattern,'',text)\n",
    "#     white paper 版本一 效果不好\n",
    "    # 优先级别 bp1 bp2 bp3\n",
    "#     bp_pattern_law = '版权声明[^\\s]+追究其相关法律责任。'\n",
    "#     bp_pattern1 = r'目录.*?披露发展报告（\\d{4}年）' # 只针对AZ08.pdf\n",
    "#     bp_pattern2 = r'目录.*?白皮书.*?（\\d{4}年）'\n",
    "#     bp_pattern3 = r'目录.*?白皮书'\n",
    "#     bp_pattern = bp_pattern_law  +'|'+bp_pattern1+'|'+bp_pattern2+'|'+bp_pattern3\n",
    "#     text = re.sub(bp_pattern,'',text)\n",
    "    \n",
    "#     print(text)\n",
    "    \n",
    "    return text\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T05:00:33.891679Z",
     "start_time": "2024-11-08T05:00:33.845683Z"
    }
   },
   "outputs": [],
   "source": [
    "for pdf_id in pdf_text.keys():\n",
    "    pdf_text[pdf_id] = filter_text(pdf_text[pdf_id])\n",
    "with open('AZ.txt','w',encoding = 'utf-8') as file:\n",
    "    pdf_all = ''.join(list(pdf_text.values())).encode('utf-8', 'replace').decode('utf-8')\n",
    "    file.write( pdf_all)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T05:00:33.986475Z",
     "start_time": "2024-11-08T05:00:33.910830Z"
    }
   },
   "outputs": [],
   "source": [
    "# from langchain_community.document_loaders import TextLoader\n",
    "# import re\n",
    "# from typing import List\n",
    "\n",
    "# class ChineseTextSplitter(CharacterTextSplitter):\n",
    "#     def __init__(self, pdf: bool = False, sentence_size: int = 250, **kwargs):\n",
    "#         super().__init__(**kwargs)\n",
    "#         self.pdf = pdf\n",
    "#         self.sentence_size = sentence_size\n",
    "\n",
    "#     def split_text(self, text: str) -> List[str]:\n",
    "#         if self.pdf:\n",
    "#             text = re.sub(r\"\\n{3,}\", \"\\n\", text)\n",
    "#             text = re.sub('\\s', ' ', text)\n",
    "#             text = text.replace(\"\\n\\n\", \"\")\n",
    "#         sent_sep_pattern = re.compile('([﹒﹔﹖﹗．。！？][\"’”」』]{0,2}|(?=[\"‘“「『]{1,2}|$))')  # del ：；\n",
    "#         sent_list = []\n",
    "#         for ele in sent_sep_pattern.split(text):\n",
    "#             if sent_sep_pattern.match(ele) and sent_list:\n",
    "#                 sent_list[-1] += ele\n",
    "#             elif ele:\n",
    "#                 sent_list.append(ele)\n",
    "#         return sent_list\n",
    "\n",
    "# # Load text from file\n",
    "# loader = TextLoader(\"AZ.txt\", encoding=\"utf-8\")\n",
    "# documents = loader.load()\n",
    "\n",
    "# # Split text using ChineseTextSplitter\n",
    "# text_splitter = ChineseTextSplitter(\n",
    "#     pdf=False,\n",
    "#     sentence_size=250,\n",
    "#     chunk_size=300,\n",
    "#     chunk_overlap=100,\n",
    "#     keep_separator='end'\n",
    "# )\n",
    "import json\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain.schema import Document  # Import the correct Document class\n",
    "\n",
    "# Load the segmented documents from the JSON file\n",
    "with open('segmented_docs.json', 'r', encoding='utf-8') as f:\n",
    "    segmented_docs = json.load(f)\n",
    "\n",
    "# Convert the loaded JSON data to the required format\n",
    "docs = [Document(page_content=doc['page_content'], metadata=doc['metadata']) for doc in segmented_docs]\n",
    "\n",
    "# Now `docs` contains the segmented documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T05:00:34.032943Z",
     "start_time": "2024-11-08T05:00:34.018943Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11683"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 文本块向量化（比赛限定使用bge-large-zh-v1.5模型）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-11-08T05:00:34.066942Z"
    },
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10050/1665006100.py:1: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings(model_name=EMB_MODEL, show_progress=True)\n",
      "Batches: 100%|██████████| 366/366 [00:14<00:00, 25.21it/s]\n"
     ]
    }
   ],
   "source": [
    "embeddings = HuggingFaceEmbeddings(model_name=EMB_MODEL, show_progress=True)\n",
    "vectordb = FAISS.from_documents(   \n",
    "    documents=docs,\n",
    "    embedding=embeddings,\n",
    ")\n",
    "\n",
    "vectordb.save_local(PERSIST_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 混合检索器\n",
    "\n",
    "#### bm25 \n",
    "- k1 较高的 k1 值意味着词频对评分的影响更大。\n",
    "- b  当 b=1 时，文档长度的影响最大；当b = 0 时，文档长度不影响评分。\n",
    "- langchain 默认切分英文split()，中文需要jieba分词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T04:59:29.647477200Z",
     "start_time": "2024-11-08T03:41:11.920515Z"
    }
   },
   "outputs": [],
   "source": [
    "import jieba\n",
    "dense_retriever = vectordb.as_retriever(search_kwargs={\"k\": 5})\n",
    "bm25_retriever = BM25Retriever.from_documents(\n",
    "    docs, \n",
    "    k=5, \n",
    "    bm25_params={\"k1\": 1.5, \"b\": 0.75}, \n",
    "    preprocess_func=jieba.lcut\n",
    ")\n",
    "ensemble_retriever = EnsembleRetriever(retrievers=[bm25_retriever, dense_retriever], weights=[0.4, 0.6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 文本召回和重排"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T04:59:29.648479200Z",
     "start_time": "2024-11-08T03:57:24.733084Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 49.88it/s]\n",
      "  1%|          | 1/100 [00:00<00:46,  2.13it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 95.08it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 96.25it/s]\n",
      "  3%|▎         | 3/100 [00:00<00:17,  5.64it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 95.28it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 96.93it/s]\n",
      "  5%|▌         | 5/100 [00:00<00:12,  7.81it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 96.29it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 94.83it/s]\n",
      "  7%|▋         | 7/100 [00:00<00:10,  8.78it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 95.98it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 95.96it/s]\n",
      "  9%|▉         | 9/100 [00:01<00:09,  9.27it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 95.93it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 94.52it/s]\n",
      " 11%|█         | 11/100 [00:01<00:09,  9.49it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 98.07it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 95.90it/s]\n",
      " 13%|█▎        | 13/100 [00:01<00:08, 10.64it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 95.39it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 96.33it/s]\n",
      " 15%|█▌        | 15/100 [00:01<00:07, 11.20it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 97.49it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 97.72it/s]\n",
      " 17%|█▋        | 17/100 [00:01<00:07, 11.33it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 98.75it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 98.21it/s]\n",
      " 19%|█▉        | 19/100 [00:02<00:07, 11.44it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 97.71it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 97.57it/s]\n",
      " 21%|██        | 21/100 [00:02<00:06, 11.83it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 97.49it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 98.59it/s]\n",
      " 23%|██▎       | 23/100 [00:02<00:06, 12.29it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 98.40it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 98.63it/s]\n",
      " 25%|██▌       | 25/100 [00:02<00:06, 11.99it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 98.93it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 98.96it/s]\n",
      " 27%|██▋       | 27/100 [00:02<00:05, 12.45it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 99.86it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 97.54it/s]\n",
      " 29%|██▉       | 29/100 [00:02<00:05, 12.97it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 96.74it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 96.49it/s]\n",
      " 31%|███       | 31/100 [00:02<00:05, 12.88it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 97.46it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 97.28it/s]\n",
      " 33%|███▎      | 33/100 [00:03<00:05, 12.70it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 92.76it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 95.35it/s]\n",
      " 35%|███▌      | 35/100 [00:03<00:05, 12.87it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 95.46it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 95.22it/s]\n",
      " 37%|███▋      | 37/100 [00:03<00:05, 12.41it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 95.70it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 96.45it/s]\n",
      " 39%|███▉      | 39/100 [00:03<00:05, 11.85it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 96.23it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 96.40it/s]\n",
      " 41%|████      | 41/100 [00:03<00:04, 12.07it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 97.01it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 97.16it/s]\n",
      " 43%|████▎     | 43/100 [00:03<00:04, 12.50it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 94.36it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 95.78it/s]\n",
      " 45%|████▌     | 45/100 [00:04<00:04, 11.51it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 96.73it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 96.96it/s]\n",
      " 47%|████▋     | 47/100 [00:04<00:04, 12.23it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 95.97it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 96.11it/s]\n",
      " 49%|████▉     | 49/100 [00:04<00:04, 12.58it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 93.83it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 98.52it/s]\n",
      " 51%|█████     | 51/100 [00:04<00:03, 12.78it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 99.17it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 98.25it/s]\n",
      " 53%|█████▎    | 53/100 [00:04<00:03, 12.88it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 96.11it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 97.89it/s]\n",
      " 55%|█████▌    | 55/100 [00:04<00:03, 12.91it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 95.94it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 96.56it/s]\n",
      " 57%|█████▋    | 57/100 [00:04<00:03, 13.62it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 95.61it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 95.33it/s]\n",
      " 59%|█████▉    | 59/100 [00:05<00:03, 13.28it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 97.60it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 98.12it/s]\n",
      " 61%|██████    | 61/100 [00:05<00:02, 13.65it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 98.03it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 98.12it/s]\n",
      " 63%|██████▎   | 63/100 [00:05<00:02, 13.69it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 97.81it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 94.54it/s]\n",
      " 65%|██████▌   | 65/100 [00:05<00:02, 13.07it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 98.73it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 98.58it/s]\n",
      " 67%|██████▋   | 67/100 [00:05<00:02, 13.01it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 97.18it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 98.53it/s]\n",
      " 69%|██████▉   | 69/100 [00:05<00:02, 12.57it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 98.75it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 98.85it/s]\n",
      " 71%|███████   | 71/100 [00:06<00:02, 12.24it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 97.94it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 97.56it/s]\n",
      " 73%|███████▎  | 73/100 [00:06<00:02, 11.95it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 97.24it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 97.79it/s]\n",
      " 75%|███████▌  | 75/100 [00:06<00:02, 11.75it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 98.26it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 97.27it/s]\n",
      " 77%|███████▋  | 77/100 [00:06<00:01, 12.24it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 95.63it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 98.00it/s]\n",
      " 79%|███████▉  | 79/100 [00:06<00:01, 12.67it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 98.03it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 97.76it/s]\n",
      " 81%|████████  | 81/100 [00:06<00:01, 13.35it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 95.21it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 96.34it/s]\n",
      " 83%|████████▎ | 83/100 [00:07<00:01, 13.03it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 96.43it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 94.03it/s]\n",
      " 85%|████████▌ | 85/100 [00:07<00:01, 13.32it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 97.03it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 95.15it/s]\n",
      " 87%|████████▋ | 87/100 [00:07<00:00, 13.15it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 97.14it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 97.57it/s]\n",
      " 89%|████████▉ | 89/100 [00:07<00:00, 13.41it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 96.94it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 97.07it/s]\n",
      " 91%|█████████ | 91/100 [00:07<00:00, 13.65it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 97.01it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 96.95it/s]\n",
      " 93%|█████████▎| 93/100 [00:07<00:00, 13.27it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 98.29it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 98.58it/s]\n",
      " 95%|█████████▌| 95/100 [00:07<00:00, 13.17it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 96.48it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 96.31it/s]\n",
      " 97%|█████████▋| 97/100 [00:08<00:00, 13.18it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 95.50it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 96.37it/s]\n",
      " 99%|█████████▉| 99/100 [00:08<00:00, 11.96it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 95.53it/s]\n",
      "100%|██████████| 100/100 [00:08<00:00, 11.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我们坚定践行网络强国、数字中国、智慧社会战略部署，今天的中国联通，正在从传统运营商加速向数字科技领军企业转变，实现了四个维度的转型升级：一是联接规模和联接结构升维，从过去的连接人为主拓展到连接人机物，大力发展物联网和工业互联网；二是核心功能升维，从以基础连接为主发展到大联接、大计算、大数据、大应用、大安全五大主责主业；三是服务和赋能水平升维，以5G、云计算、大数据、人工智能、区块链为代表的新一代信息技术和实体经济的结合，服务数字政府、数字社会、数字经济的能力不断增强；四是发展理念升维，\n"
     ]
    }
   ],
   "source": [
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors import CrossEncoderReranker\n",
    "from langchain_community.cross_encoders import HuggingFaceCrossEncoder\n",
    "\n",
    "def rerank(questions, retriever, top_n=1, cut_len=384):\n",
    "    rerank_model = HuggingFaceCrossEncoder(model_name=RERANK_MODEL)\n",
    "    compressor = CrossEncoderReranker(model=rerank_model, top_n=top_n)\n",
    "    compression_retriever = ContextualCompressionRetriever(\n",
    "        base_compressor=compressor, base_retriever=retriever\n",
    "    )\n",
    "    rerank_answers = []\n",
    "    for question in tqdm(questions):\n",
    "        relevant_docs = compression_retriever.invoke(question)\n",
    "        answer=''\n",
    "        for rd in relevant_docs:\n",
    "            answer += rd.page_content\n",
    "        rerank_answers.append(answer[:245])\n",
    "    return rerank_answers\n",
    "\n",
    "questions = list(query['question'].values)\n",
    "rerank_answers = rerank(questions, ensemble_retriever)\n",
    "print(rerank_answers[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 提交"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T04:59:29.648479200Z",
     "start_time": "2024-11-07T17:51:49.193140Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "embedding sentences: 100%|██████████| 25/25 [00:00<00:00, 56.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emb_model max_seq_length:  512\n",
      "emb_model embeddings_shape:  1024\n"
     ]
    }
   ],
   "source": [
    "def emb(answers, emb_batch_size = 4):\n",
    "    model = SentenceTransformer(EMB_MODEL, trust_remote_code=True)\n",
    "    all_sentence_embeddings = []\n",
    "    for i in tqdm(range(0, len(answers), emb_batch_size), desc=\"embedding sentences\"):\n",
    "        batch_sentences = answers[i:i+emb_batch_size]\n",
    "        sentence_embeddings = model.encode(batch_sentences, normalize_embeddings=True)\n",
    "        all_sentence_embeddings.append(sentence_embeddings)\n",
    "    all_sentence_embeddings = np.concatenate(all_sentence_embeddings, axis=0)\n",
    "    print('emb_model max_seq_length: ', model.max_seq_length)\n",
    "    print('emb_model embeddings_shape: ', all_sentence_embeddings.shape[-1])\n",
    "    del model\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    return all_sentence_embeddings\n",
    "\n",
    "all_sentence_embeddings = emb(rerank_answers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T04:59:29.648479200Z",
     "start_time": "2024-11-07T17:51:52.309769Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ques_id</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>根据年度报告，2022年中国联通在向数字科技领军企业转变的过程中实现了哪些维度的转型升级？</td>\n",
       "      <td>我们坚定践行网络强国、数字中国、智慧社会战略部署，今天的中国联通，正在从传统运营商加速向数字...</td>\n",
       "      <td>-0.029152686,-0.010147623,-0.0077438904,0.0005...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>告诉我2022年联通产业互联网收入的同比增长速度。</td>\n",
       "      <td>产业互联网业务收入同比增长43%，达到人民币167亿元，占整体主营业务收入比例提高至13%。</td>\n",
       "      <td>-0.019969385,3.1673717e-05,-0.020098232,0.0325...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>根据2022年度报告，中国联通的企业定位是什么？</td>\n",
       "      <td>中国联通将继续围绕国家所需、产业链供应链所困，以战略性新兴产业和未来产业为主线，全力成为国家...</td>\n",
       "      <td>-0.028505648,-0.0656241,-0.054282375,0.0185620...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2022年联通在“大联接”和“大数据”业务上取得了什么成果？</td>\n",
       "      <td>“大联接”方面，中国联通抢抓“双千兆”“物超人”发展机遇，坚持量质构效协同发展。</td>\n",
       "      <td>-0.021224735,-0.015668493,-0.05333152,0.034375...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2022年上半年，联通在精品网络建设上有什么成果？</td>\n",
       "      <td>适度加大战略投入，基础网络能力大幅提升中国联通始终坚持网络在企业发展中的基础地位，适度加大战...</td>\n",
       "      <td>-0.020395445,-0.031567223,-0.06338017,0.000282...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ques_id                                       question  \\\n",
       "0        1  根据年度报告，2022年中国联通在向数字科技领军企业转变的过程中实现了哪些维度的转型升级？   \n",
       "1        2                      告诉我2022年联通产业互联网收入的同比增长速度。   \n",
       "2        3                       根据2022年度报告，中国联通的企业定位是什么？   \n",
       "3        4                 2022年联通在“大联接”和“大数据”业务上取得了什么成果？   \n",
       "4        5                      2022年上半年，联通在精品网络建设上有什么成果？   \n",
       "\n",
       "                                              answer  \\\n",
       "0  我们坚定践行网络强国、数字中国、智慧社会战略部署，今天的中国联通，正在从传统运营商加速向数字...   \n",
       "1     产业互联网业务收入同比增长43%，达到人民币167亿元，占整体主营业务收入比例提高至13%。   \n",
       "2  中国联通将继续围绕国家所需、产业链供应链所困，以战略性新兴产业和未来产业为主线，全力成为国家...   \n",
       "3           “大联接”方面，中国联通抢抓“双千兆”“物超人”发展机遇，坚持量质构效协同发展。   \n",
       "4  适度加大战略投入，基础网络能力大幅提升中国联通始终坚持网络在企业发展中的基础地位，适度加大战...   \n",
       "\n",
       "                                           embedding  \n",
       "0  -0.029152686,-0.010147623,-0.0077438904,0.0005...  \n",
       "1  -0.019969385,3.1673717e-05,-0.020098232,0.0325...  \n",
       "2  -0.028505648,-0.0656241,-0.054282375,0.0185620...  \n",
       "3  -0.021224735,-0.015668493,-0.05333152,0.034375...  \n",
       "4  -0.020395445,-0.031567223,-0.06338017,0.000282...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub['answer'] = rerank_answers\n",
    "sub['embedding']= [','.join([str(a) for a in all_sentence_embeddings[i]]) for i in range(len(all_sentence_embeddings))]\n",
    "sub.to_csv('submit3.0.csv', index=None)\n",
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 5782812,
     "sourceId": 9501900,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5819690,
     "sourceId": 9551539,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5831812,
     "sourceId": 9568175,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30787,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python (train39)",
   "language": "python",
   "name": "train39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
