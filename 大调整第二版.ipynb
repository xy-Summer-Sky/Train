{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T04:59:50.579193Z",
     "start_time": "2024-11-08T04:59:39.348644Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/train39/lib/python3.9/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:13: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyPDFDirectoryLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter, CharacterTextSplitter,TokenTextSplitter\n",
    "from langchain_community.embeddings.huggingface import HuggingFaceEmbeddings\n",
    "from langchain_community.retrievers.bm25 import BM25Retriever\n",
    "from langchain.retrievers import EnsembleRetriever\n",
    "from langchain_community.vectorstores import Chroma, FAISS\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableParallel\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "import gc\n",
    "import re\n",
    "from IPython.display import display\n",
    "\n",
    "DOCS_DIR = './A/A_document'\n",
    "EMB_MODEL = './bge-large-zh-v1.5'\n",
    "RERANK_MODEL = \"./bge-reranker-large\"\n",
    "PERSIST_DIR = './vectordb' \n",
    "QUERY_DIR = './A/A_question.csv'\n",
    "SUB_DIR = './submit_example.csv'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T04:59:50.657198Z",
     "start_time": "2024-11-08T04:59:50.596199Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ques_id</th>\n",
       "      <th>question</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>根据年度报告，2022年中国联通在向数字科技领军企业转变的过程中实现了哪些维度的转型升级？</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>告诉我2022年联通产业互联网收入的同比增长速度。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>根据2022年度报告，中国联通的企业定位是什么？</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ques_id                                       question\n",
       "0        1  根据年度报告，2022年中国联通在向数字科技领军企业转变的过程中实现了哪些维度的转型升级？\n",
       "1        2                      告诉我2022年联通产业互联网收入的同比增长速度。\n",
       "2        3                       根据2022年度报告，中国联通的企业定位是什么？"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ques_id</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>根据年度报告，2022年中国联通在向数字科技领军企业转变的过程中实现了哪些维度的转型升级？</td>\n",
       "      <td>我们坚定践行网络强国、数字中国、智慧社会战略部署，今天的中国联通，正在从传统运营商加速向数字...</td>\n",
       "      <td>-0.02707982249557972,-0.009818901307880878,-0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>告诉我2022年联通产业互联网收入的同比增长速度。</td>\n",
       "      <td>我们坚定践行网络强国、数字中国、智慧社会战略部署，今天的中国联通，正在从传统运营商加速向数字...</td>\n",
       "      <td>-0.02707982249557972,-0.009818901307880878,-0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>根据2022年度报告，中国联通的企业定位是什么？</td>\n",
       "      <td>我们坚定践行网络强国、数字中国、智慧社会战略部署，今天的中国联通，正在从传统运营商加速向数字...</td>\n",
       "      <td>-0.02707982249557972,-0.009818901307880878,-0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ques_id                                       question  \\\n",
       "0        1  根据年度报告，2022年中国联通在向数字科技领军企业转变的过程中实现了哪些维度的转型升级？   \n",
       "1        2                      告诉我2022年联通产业互联网收入的同比增长速度。   \n",
       "2        3                       根据2022年度报告，中国联通的企业定位是什么？   \n",
       "\n",
       "                                              answer  \\\n",
       "0  我们坚定践行网络强国、数字中国、智慧社会战略部署，今天的中国联通，正在从传统运营商加速向数字...   \n",
       "1  我们坚定践行网络强国、数字中国、智慧社会战略部署，今天的中国联通，正在从传统运营商加速向数字...   \n",
       "2  我们坚定践行网络强国、数字中国、智慧社会战略部署，今天的中国联通，正在从传统运营商加速向数字...   \n",
       "\n",
       "                                           embedding  \n",
       "0  -0.02707982249557972,-0.009818901307880878,-0....  \n",
       "1  -0.02707982249557972,-0.009818901307880878,-0....  \n",
       "2  -0.02707982249557972,-0.009818901307880878,-0....  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "query = pd.read_csv(QUERY_DIR)\n",
    "sub = pd.read_csv(\"./submit_example.csv\")\n",
    "display(query.head(3))\n",
    "display(sub.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PDF文档解析和切分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T05:00:33.751532Z",
     "start_time": "2024-11-08T04:59:51.353879Z"
    }
   },
   "outputs": [],
   "source": [
    "loader = PyPDFDirectoryLoader(DOCS_DIR)\n",
    "pages = loader.load_and_split()\n",
    "pdf_list = os.listdir(DOCS_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T05:00:33.798171Z",
     "start_time": "2024-11-08T05:00:33.764543Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 114/114 [00:00<00:00, 8256.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "key:pdf value:text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "pdf_text = { pdf_page.metadata['source'][-8:]:'' for pdf_page  in pages }\n",
    "for pdf in tqdm(pdf_list):\n",
    "    for pdf_page in pages:\n",
    "        if pdf in pdf_page.metadata['source']:\n",
    "            pdf_text[pdf] += pdf_page.page_content\n",
    "        else:\n",
    "            continue\n",
    "print('key:pdf value:text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T05:00:33.827680Z",
     "start_time": "2024-11-08T05:00:33.814687Z"
    }
   },
   "outputs": [],
   "source": [
    "def filter_text(text):\n",
    "    # 页码清除 效果不好\n",
    "#     page_id_pattern1 = r'\\n\\d+\\s*/\\s*\\d+\\s*\\n'\n",
    "#     page_id_pattern2 = r'\\n\\d+\\n'\n",
    "#     page_id_pattern3 = r'\\n\\d+\\s*?'\n",
    "\n",
    "#     page_id_pattern = page_id_pattern1+'|'+page_id_pattern2+'|'+page_id_pattern3\n",
    "#     text = re.sub(page_id_pattern,'',text)\n",
    "    \n",
    "    # '\\n', ' ' 删除\n",
    "    text = text.replace('\\n','').replace(' ','')\n",
    "    \n",
    "    # 删除页码\n",
    "    \n",
    "    # 删除本文档为2024CCFBDC***\n",
    "    head_pattern = '本文档为2024CCFBDCI比赛用语料的一部分。[^\\s]+仅允许在本次比赛中使用。'\n",
    "    # news_pattern\n",
    "    pattern1 = r\"发布时间：[^\\s]+发布人：新闻宣传中心\"\n",
    "    pattern2 = r\"发布时间：[^\\s]+发布人：新闻发布人\"\n",
    "    pattern3 =  r'发布时间：\\d{4}年\\d{1,2}月\\d{1,2}日'\n",
    "    news_pattern = head_pattern+'|'+pattern1+'|'+pattern2+'|'+pattern3\n",
    "    text = re.sub(news_pattern,'',text)\n",
    "    \n",
    "    \n",
    "    # report_pattern\n",
    "    report_pattern1 = '第一节重要提示[^\\s]+本次利润分配方案尚需提交本公司股东大会审议。'\n",
    "    report_pattern12 = '一重要提示[^\\s]+股东大会审议。'\n",
    "    report_pattern13 = '一、重要提示[^\\s]+季度报告未经审计。'\n",
    "    report_pattern2 = '本公司董事会及全体董事保证本公告内容不存在任何虚假记载、[^\\s]+季度财务报表是否经审计□是√否'\n",
    "    report_pattern3 = '中国联合网络通信股份有限公司（简称“公司”）董事会审计委员会根据相关法律法规、[^\\s]+汇报如下：'\n",
    "    report_pattern = report_pattern1+'|'+report_pattern12+'|'+report_pattern13+'|'+report_pattern2+'|'+report_pattern3\n",
    "    text = re.sub( report_pattern,'',text)\n",
    "#     white paper 版本一 效果不好\n",
    "    # 优先级别 bp1 bp2 bp3\n",
    "#     bp_pattern_law = '版权声明[^\\s]+追究其相关法律责任。'\n",
    "#     bp_pattern1 = r'目录.*?披露发展报告（\\d{4}年）' # 只针对AZ08.pdf\n",
    "#     bp_pattern2 = r'目录.*?白皮书.*?（\\d{4}年）'\n",
    "#     bp_pattern3 = r'目录.*?白皮书'\n",
    "#     bp_pattern = bp_pattern_law  +'|'+bp_pattern1+'|'+bp_pattern2+'|'+bp_pattern3\n",
    "#     text = re.sub(bp_pattern,'',text)\n",
    "    \n",
    "#     print(text)\n",
    "    \n",
    "    return text\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T05:00:33.891679Z",
     "start_time": "2024-11-08T05:00:33.845683Z"
    }
   },
   "outputs": [],
   "source": [
    "for pdf_id in pdf_text.keys():\n",
    "    pdf_text[pdf_id] = filter_text(pdf_text[pdf_id])\n",
    "with open('AZ.txt','w',encoding = 'utf-8') as file:\n",
    "    pdf_all = ''.join(list(pdf_text.values())).encode('utf-8', 'replace').decode('utf-8')\n",
    "    file.write( pdf_all)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T05:00:33.986475Z",
     "start_time": "2024-11-08T05:00:33.910830Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "loader = TextLoader(\"AZ.txt\",encoding=\"utf-8\")\n",
    "documents = loader.load()\n",
    "#分割文本\n",
    "text_splitter = RecursiveCharacterTextSplitter(        \n",
    "        chunk_size=200,             \n",
    "        chunk_overlap=50,\n",
    "        separators = [\"。\", \"！\", \"？\"],\n",
    "        keep_separator='end',\n",
    "    )\n",
    "docs = text_splitter.split_documents(documents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T05:00:34.032943Z",
     "start_time": "2024-11-08T05:00:34.018943Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4343"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 文本块向量化（比赛限定使用bge-large-zh-v1.5模型）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-11-08T05:00:34.066942Z"
    },
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1561/1665006100.py:1: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings(model_name=EMB_MODEL, show_progress=True)\n",
      "Batches: 100%|██████████| 136/136 [00:13<00:00, 10.13it/s]\n"
     ]
    }
   ],
   "source": [
    "embeddings = HuggingFaceEmbeddings(model_name=EMB_MODEL, show_progress=True)\n",
    "vectordb = FAISS.from_documents(   \n",
    "    documents=docs,\n",
    "    embedding=embeddings,\n",
    ")\n",
    "\n",
    "vectordb.save_local(PERSIST_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 混合检索器\n",
    "\n",
    "#### bm25 \n",
    "- k1 较高的 k1 值意味着词频对评分的影响更大。\n",
    "- b  当 b=1 时，文档长度的影响最大；当b = 0 时，文档长度不影响评分。\n",
    "- langchain 默认切分英文split()，中文需要jieba分词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T04:59:29.647477200Z",
     "start_time": "2024-11-08T03:41:11.920515Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Dumping model to file cache /tmp/jieba.cache\n",
      "Loading model cost 0.533 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    }
   ],
   "source": [
    "import jieba\n",
    "dense_retriever = vectordb.as_retriever(search_kwargs={\"k\": 5})\n",
    "bm25_retriever = BM25Retriever.from_documents(\n",
    "    docs, \n",
    "    k=5, \n",
    "    bm25_params={\"k1\": 1.2, \"b\": 0.75}, \n",
    "    preprocess_func=jieba.lcut\n",
    ")\n",
    "ensemble_retriever = EnsembleRetriever(retrievers=[bm25_retriever, dense_retriever], weights=[0.4, 0.6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 文本召回和重排"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T04:59:29.648479200Z",
     "start_time": "2024-11-08T03:57:24.733084Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 57.51it/s]\n",
      "  1%|          | 1/100 [00:01<01:47,  1.08s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 97.38it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 95.52it/s]\n",
      "  3%|▎         | 3/100 [00:01<00:32,  2.97it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 101.60it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 103.55it/s]\n",
      "  5%|▌         | 5/100 [00:01<00:19,  4.93it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 101.17it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 99.00it/s]\n",
      "  7%|▋         | 7/100 [00:01<00:15,  5.96it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 101.71it/s]\n",
      "  8%|▊         | 8/100 [00:01<00:14,  6.41it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 100.78it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 101.37it/s]\n",
      " 10%|█         | 10/100 [00:01<00:11,  7.69it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 101.18it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 99.26it/s]\n",
      " 12%|█▏        | 12/100 [00:02<00:10,  8.27it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 100.29it/s]\n",
      " 13%|█▎        | 13/100 [00:02<00:10,  8.47it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 100.74it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 99.58it/s]\n",
      " 15%|█▌        | 15/100 [00:02<00:08,  9.87it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 99.85it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 103.52it/s]\n",
      " 17%|█▋        | 17/100 [00:02<00:07, 11.32it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 100.41it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 101.77it/s]\n",
      " 19%|█▉        | 19/100 [00:02<00:06, 12.20it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 101.88it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 102.43it/s]\n",
      " 21%|██        | 21/100 [00:02<00:06, 13.00it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 100.72it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 100.42it/s]\n",
      " 23%|██▎       | 23/100 [00:02<00:05, 13.61it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 99.46it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 103.19it/s]\n",
      " 25%|██▌       | 25/100 [00:03<00:05, 13.80it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 102.50it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 102.02it/s]\n",
      " 27%|██▋       | 27/100 [00:03<00:04, 14.81it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 104.55it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 101.43it/s]\n",
      " 29%|██▉       | 29/100 [00:03<00:04, 14.54it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 103.83it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 104.53it/s]\n",
      " 31%|███       | 31/100 [00:03<00:04, 15.16it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 102.28it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 100.78it/s]\n",
      " 33%|███▎      | 33/100 [00:03<00:04, 15.60it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 102.25it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 103.71it/s]\n",
      " 35%|███▌      | 35/100 [00:03<00:04, 14.81it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 105.93it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 95.38it/s]\n",
      " 37%|███▋      | 37/100 [00:03<00:04, 14.43it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 94.55it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 103.06it/s]\n",
      " 39%|███▉      | 39/100 [00:03<00:04, 14.37it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 101.90it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 101.63it/s]\n",
      " 41%|████      | 41/100 [00:04<00:04, 14.48it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 104.65it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 98.30it/s]\n",
      " 43%|████▎     | 43/100 [00:04<00:03, 14.87it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 98.59it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 98.82it/s]\n",
      " 45%|████▌     | 45/100 [00:04<00:03, 14.32it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 103.89it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 104.30it/s]\n",
      " 47%|████▋     | 47/100 [00:04<00:03, 15.40it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 104.03it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 100.40it/s]\n",
      " 49%|████▉     | 49/100 [00:04<00:03, 13.69it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 102.76it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 103.93it/s]\n",
      " 51%|█████     | 51/100 [00:04<00:03, 14.72it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 104.73it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 102.79it/s]\n",
      " 53%|█████▎    | 53/100 [00:04<00:03, 15.51it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 100.33it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 105.50it/s]\n",
      " 55%|█████▌    | 55/100 [00:05<00:02, 15.57it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 105.84it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 105.27it/s]\n",
      " 57%|█████▋    | 57/100 [00:05<00:02, 15.80it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 106.00it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 102.86it/s]\n",
      " 59%|█████▉    | 59/100 [00:05<00:02, 15.59it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 103.81it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 104.16it/s]\n",
      " 61%|██████    | 61/100 [00:05<00:02, 16.04it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 104.00it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 102.22it/s]\n",
      " 63%|██████▎   | 63/100 [00:05<00:02, 16.63it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 102.99it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 100.69it/s]\n",
      " 65%|██████▌   | 65/100 [00:05<00:02, 16.71it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 100.07it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 101.94it/s]\n",
      " 67%|██████▋   | 67/100 [00:05<00:01, 16.75it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 103.17it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 103.90it/s]\n",
      " 69%|██████▉   | 69/100 [00:05<00:01, 16.27it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 104.74it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 104.05it/s]\n",
      " 71%|███████   | 71/100 [00:06<00:01, 16.23it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 104.44it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 100.58it/s]\n",
      " 73%|███████▎  | 73/100 [00:06<00:01, 16.02it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 102.75it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 101.42it/s]\n",
      " 75%|███████▌  | 75/100 [00:06<00:01, 15.85it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 104.80it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 104.12it/s]\n",
      " 77%|███████▋  | 77/100 [00:06<00:01, 16.31it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 104.15it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 103.68it/s]\n",
      " 79%|███████▉  | 79/100 [00:06<00:01, 16.71it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 103.81it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 105.35it/s]\n",
      " 81%|████████  | 81/100 [00:06<00:01, 17.16it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 104.83it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 102.18it/s]\n",
      " 83%|████████▎ | 83/100 [00:06<00:00, 17.31it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 103.55it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 103.59it/s]\n",
      " 85%|████████▌ | 85/100 [00:06<00:00, 17.83it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 103.57it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 102.63it/s]\n",
      " 87%|████████▋ | 87/100 [00:06<00:00, 17.94it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 104.64it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 104.73it/s]\n",
      " 89%|████████▉ | 89/100 [00:07<00:00, 17.68it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 105.67it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 101.60it/s]\n",
      " 91%|█████████ | 91/100 [00:07<00:00, 17.65it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 103.97it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 103.32it/s]\n",
      " 93%|█████████▎| 93/100 [00:07<00:00, 17.18it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 104.66it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 103.59it/s]\n",
      " 95%|█████████▌| 95/100 [00:07<00:00, 17.10it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 103.97it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 101.74it/s]\n",
      " 97%|█████████▋| 97/100 [00:07<00:00, 17.36it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 103.16it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 102.55it/s]\n",
      " 99%|█████████▉| 99/100 [00:07<00:00, 16.91it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 103.22it/s]\n",
      "100%|██████████| 100/100 [00:07<00:00, 12.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我们坚定践行网络强国、数字中国、智慧社会战略部署，今天的中国联通，正在从传统运营商加速向数字科技领军企业转变，实现了四个维度的转型升级：一是联接规模和联接结构升维，从过去的连接人为主拓展到连接人机物，大力发展物联网和工业互联网；二是核心功能升维，从以基础连接为主发展到大联接、大计算、大数据、大应用、大安全五大主责主业；三是服务和赋能水平升维，以5G、云计算、大数据、人工智能、区块链为代表的新一代信\n"
     ]
    }
   ],
   "source": [
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors import CrossEncoderReranker\n",
    "from langchain_community.cross_encoders import HuggingFaceCrossEncoder\n",
    "\n",
    "def rerank(questions, retriever, top_n=1, cut_len=245):\n",
    "    rerank_model = HuggingFaceCrossEncoder(model_name=RERANK_MODEL)\n",
    "    compressor = CrossEncoderReranker(model=rerank_model, top_n=top_n)\n",
    "    compression_retriever = ContextualCompressionRetriever(\n",
    "        base_compressor=compressor, base_retriever=retriever\n",
    "    )\n",
    "    rerank_answers = []\n",
    "    for question in tqdm(questions):\n",
    "        relevant_docs = compression_retriever.invoke(question)\n",
    "        answer = ''\n",
    "        for rd in relevant_docs:\n",
    "            answer += rd.page_content\n",
    "        rerank_answers.append(answer[:cut_len])  # 限制返回结果的最大长度\n",
    "    return rerank_answers\n",
    "\n",
    "# 调用改进后的rerank函数\n",
    "questions = list(query['question'].values)\n",
    "rerank_answers = rerank(questions, ensemble_retriever, top_n=1, cut_len=200)  # 调整cut_len参数\n",
    "print(rerank_answers[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 提交"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T04:59:29.648479200Z",
     "start_time": "2024-11-07T17:51:49.193140Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "embedding sentences: 100%|██████████| 25/25 [00:00<00:00, 48.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emb_model max_seq_length:  512\n",
      "emb_model embeddings_shape:  1024\n"
     ]
    }
   ],
   "source": [
    "def emb(answers, emb_batch_size = 4):\n",
    "    model = SentenceTransformer(EMB_MODEL, trust_remote_code=True)\n",
    "    all_sentence_embeddings = []\n",
    "    for i in tqdm(range(0, len(answers), emb_batch_size), desc=\"embedding sentences\"):\n",
    "        batch_sentences = answers[i:i+emb_batch_size]\n",
    "        sentence_embeddings = model.encode(batch_sentences, normalize_embeddings=True)\n",
    "        all_sentence_embeddings.append(sentence_embeddings)\n",
    "    all_sentence_embeddings = np.concatenate(all_sentence_embeddings, axis=0)\n",
    "    print('emb_model max_seq_length: ', model.max_seq_length)\n",
    "    print('emb_model embeddings_shape: ', all_sentence_embeddings.shape[-1])\n",
    "    del model\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    return all_sentence_embeddings\n",
    "\n",
    "all_sentence_embeddings = emb(rerank_answers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T04:59:29.648479200Z",
     "start_time": "2024-11-07T17:51:52.309769Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ques_id</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>根据年度报告，2022年中国联通在向数字科技领军企业转变的过程中实现了哪些维度的转型升级？</td>\n",
       "      <td>我们坚定践行网络强国、数字中国、智慧社会战略部署，今天的中国联通，正在从传统运营商加速向数字...</td>\n",
       "      <td>-0.02981867,-0.008252482,-0.006214926,0.004394...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>告诉我2022年联通产业互联网收入的同比增长速度。</td>\n",
       "      <td>做好稳盘托底，个人及家庭市场发展稳健，基础业务实现规模价值双提升；加快创新转型，汇聚独特优势...</td>\n",
       "      <td>-0.031448577,-0.007706013,-0.01623609,0.023967...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>根据2022年度报告，中国联通的企业定位是什么？</td>\n",
       "      <td>中国联合网络通信股份有限公司2022年年度报告1公司代码：600050公司简称：中国联通中国...</td>\n",
       "      <td>-0.039142217,-0.030177027,-0.06400865,-0.01850...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2022年联通在“大联接”和“大数据”业务上取得了什么成果？</td>\n",
       "      <td>联通大数据业务保持高速发展，市场份额持续领跑行业，区块链专利储备央企第一。“大应用”方面，公...</td>\n",
       "      <td>-0.028371815,-0.037544142,-0.048366256,0.00225...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2022年上半年，联通在精品网络建设上有什么成果？</td>\n",
       "      <td>适度加大战略投入，基础网络能力大幅提升中国联通始终坚持网络在企业发展中的基础地位，适度加大战...</td>\n",
       "      <td>-0.013433302,-0.034780066,-0.05958391,0.007808...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ques_id                                       question  \\\n",
       "0        1  根据年度报告，2022年中国联通在向数字科技领军企业转变的过程中实现了哪些维度的转型升级？   \n",
       "1        2                      告诉我2022年联通产业互联网收入的同比增长速度。   \n",
       "2        3                       根据2022年度报告，中国联通的企业定位是什么？   \n",
       "3        4                 2022年联通在“大联接”和“大数据”业务上取得了什么成果？   \n",
       "4        5                      2022年上半年，联通在精品网络建设上有什么成果？   \n",
       "\n",
       "                                              answer  \\\n",
       "0  我们坚定践行网络强国、数字中国、智慧社会战略部署，今天的中国联通，正在从传统运营商加速向数字...   \n",
       "1  做好稳盘托底，个人及家庭市场发展稳健，基础业务实现规模价值双提升；加快创新转型，汇聚独特优势...   \n",
       "2  中国联合网络通信股份有限公司2022年年度报告1公司代码：600050公司简称：中国联通中国...   \n",
       "3  联通大数据业务保持高速发展，市场份额持续领跑行业，区块链专利储备央企第一。“大应用”方面，公...   \n",
       "4  适度加大战略投入，基础网络能力大幅提升中国联通始终坚持网络在企业发展中的基础地位，适度加大战...   \n",
       "\n",
       "                                           embedding  \n",
       "0  -0.02981867,-0.008252482,-0.006214926,0.004394...  \n",
       "1  -0.031448577,-0.007706013,-0.01623609,0.023967...  \n",
       "2  -0.039142217,-0.030177027,-0.06400865,-0.01850...  \n",
       "3  -0.028371815,-0.037544142,-0.048366256,0.00225...  \n",
       "4  -0.013433302,-0.034780066,-0.05958391,0.007808...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub['answer'] = rerank_answers\n",
    "sub['embedding']= [','.join([str(a) for a in all_sentence_embeddings[i]]) for i in range(len(all_sentence_embeddings))]\n",
    "sub.to_csv('submit4.0.csv', index=None)\n",
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'true_answer'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/train39/lib/python3.9/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'true_answer'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mF1 Score: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mf1\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Assuming 'true_answer' column in query DataFrame contains the true answers\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m true_answers \u001b[38;5;241m=\u001b[39m \u001b[43mquery\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrue_answer\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mvalues\n\u001b[1;32m     14\u001b[0m predicted_answers \u001b[38;5;241m=\u001b[39m sub[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124manswer\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues\n\u001b[1;32m     16\u001b[0m evaluate_model(true_answers, predicted_answers)\n",
      "File \u001b[0;32m~/miniconda3/envs/train39/lib/python3.9/site-packages/pandas/core/frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/miniconda3/envs/train39/lib/python3.9/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'true_answer'"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, recall_score, f1_score\n",
    "\n",
    "def evaluate_model(true_answers, predicted_answers):\n",
    "    accuracy = accuracy_score(true_answers, predicted_answers)\n",
    "    recall = recall_score(true_answers, predicted_answers, average='macro')\n",
    "    f1 = f1_score(true_answers, predicted_answers, average='macro')\n",
    "\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "\n",
    "# Assuming 'true_answer' column in query DataFrame contains the true answers\n",
    "true_answers = query['true_answer'].values\n",
    "predicted_answers = sub['answer'].values\n",
    "\n",
    "evaluate_model(true_answers, predicted_answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 5782812,
     "sourceId": 9501900,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5819690,
     "sourceId": 9551539,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5831812,
     "sourceId": 9568175,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30787,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (train39)",
   "language": "python",
   "name": "train39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
